{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0242f5f4-e8e1-4fc8-bcd9-a2e36e772f35",
   "metadata": {},
   "source": [
    "## Group Memberâ€™s Name:-\n",
    "## Muhammad Arsalan (2303.KHI.DEG.025)\n",
    "## Abdul Rehman (2303.KHI.DEG.035)\n",
    "## Arshad Shiwani (2303.KHI.DEG.026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0325b09-f1ca-40c0-be10-7db422031f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (max, min, avg, col, when, udf)\n",
    "from pyspark.sql.types import StringType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ae9ef-e770-4b13-a1b8-808456032296",
   "metadata": {},
   "source": [
    "## starting the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c7c2ab-b9ea-4863-bf95-8783e48a9edc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/29 11:00:55 WARN Utils: Your hostname, all-MS-7D35 resolves to a loopback address: 127.0.1.1; using 192.168.1.139 instead (on interface enp2s0)\n",
      "23/05/29 11:00:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/29 11:00:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data Processing\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35bc2e-e997-4848-8077-0b8fa031e066",
   "metadata": {},
   "source": [
    "## given the columns name and import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb3584f-d7d3-4ac1-a087-910e2dc0b38a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+--------+-------------------+\n",
      "|PassengerId|Survived|Passenger_class|                Name|Gender| Age|Siblings_Spouse|Par_child|          Ticket|   Fare|Cabin|Embarked|          Timestamp|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+--------+-------------------+\n",
      "|          1|       0|              3|Braund, Mr. Owen ...|  male|  22|              1|        0|       A/5 21171|   7.25| null|       S|2020-01-01 13:45:25|\n",
      "|          2|       1|              1|Cumings, Mrs. Joh...|female|  38|              1|        0|        PC 17599|71.2833|  C85|       C|2020-01-01 13:44:48|\n",
      "|          3|       1|              3|Heikkinen, Miss. ...|female|  26|              0|        0|STON/O2. 3101282|  7.925| null|       S|2020-01-01 13:38:11|\n",
      "|          4|       1|              1|Futrelle, Mrs. Ja...|female|  35|              1|        0|          113803|   53.1| C123|       S|2020-01-01 13:32:00|\n",
      "|          5|       0|              3|Allen, Mr. Willia...|  male|  35|              0|        0|          373450|   8.05| null|       S|2020-01-01 13:36:30|\n",
      "|          6|       0|              3|    Moran, Mr. James|  male|null|              0|        0|          330877| 8.4583| null|       Q|2020-01-01 13:31:39|\n",
      "|          7|       0|              1|McCarthy, Mr. Tim...|  male|  54|              0|        0|           17463|51.8625|  E46|       S|2020-01-01 13:37:31|\n",
      "|          8|       0|              3|Palsson, Master. ...|  male|   2|              3|        1|          349909| 21.075| null|       S|2020-01-01 13:49:08|\n",
      "|          9|       1|              3|Johnson, Mrs. Osc...|female|  27|              0|        2|          347742|11.1333| null|       S|2020-01-01 13:33:42|\n",
      "|         10|       1|              2|Nasser, Mrs. Nich...|female|  14|              1|        0|          237736|30.0708| null|       C|2020-01-01 13:32:53|\n",
      "|         11|       1|              3|Sandstrom, Miss. ...|female|   4|              1|        1|         PP 9549|   16.7|   G6|       S|2020-01-01 13:32:23|\n",
      "|         12|       1|              1|Bonnell, Miss. El...|female|  58|              0|        0|          113783|  26.55| C103|       S|2020-01-01 13:30:12|\n",
      "|         13|       0|              3|Saundercock, Mr. ...|  male|  20|              0|        0|       A/5. 2151|   8.05| null|       S|2020-01-01 13:33:34|\n",
      "|         14|       0|              3|Andersson, Mr. An...|  male|  39|              1|        5|          347082| 31.275| null|       S|2020-01-01 13:30:20|\n",
      "|         15|       0|              3|Vestrom, Miss. Hu...|female|  14|              0|        0|          350406| 7.8542| null|       S|2020-01-01 13:41:17|\n",
      "|         16|       1|              2|Hewlett, Mrs. (Ma...|female|  55|              0|        0|          248706|   16.0| null|       S|2020-01-01 13:34:22|\n",
      "|         17|       0|              3|Rice, Master. Eugene|  male|   2|              4|        1|          382652| 29.125| null|       Q|2020-01-01 13:41:55|\n",
      "|         18|       1|              2|Williams, Mr. Cha...|  male|null|              0|        0|          244373|   13.0| null|       S|2020-01-01 13:39:35|\n",
      "|         19|       0|              3|Vander Planke, Mr...|female|  31|              1|        0|          345763|   18.0| null|       S|2020-01-01 13:39:38|\n",
      "|         20|       1|              3|Masselmani, Mrs. ...|female|null|              0|        0|            2649|  7.225| null|       C|2020-01-01 13:36:56|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['PassengerId', 'Survived', 'Passenger_class','Name','Gender','Age','Siblings_Spouse','Par_child','Ticket','Fare','Cabin','Embarked','Timestamp']\n",
    "              \n",
    "df = spark.read.csv(\"./data/titanic.csv\",inferSchema=True)\n",
    "df = df.toDF(*columns)\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892476c-89ec-4f11-9607-8bf80baa7fbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Change the Coloums Values to Yes or No and 1 or 2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46b7696-7b30-4fcf-9ad0-a84df30af6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Survived\", when(col(\"Survived\") == 1, \"Yes\").otherwise(\"No\"))\\\n",
    "       .withColumn(\"Passenger_class\", when(col(\"Passenger_class\") == 1, \"1st\").when(col(\"Passenger_class\") == 2, '2nd').otherwise('3rd'))\\\n",
    "       .withColumn(\"Embarked\", when(col(\"Embarked\") == 'S', 'Southampton').when(col(\"Embarked\") == 'C', 'Cherbourg').otherwise('Queenstown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c9c7de-c399-4d86-a3b1-b0cbe9654645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "|PassengerId|Survived|Passenger_class|                Name|Gender| Age|Siblings_Spouse|Par_child|          Ticket|   Fare|Cabin|   Embarked|          Timestamp|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "|          1|      No|            3rd|Braund, Mr. Owen ...|  male|  22|              1|        0|       A/5 21171|   7.25| null|Southampton|2020-01-01 13:45:25|\n",
      "|          2|     Yes|            1st|Cumings, Mrs. Joh...|female|  38|              1|        0|        PC 17599|71.2833|  C85|  Cherbourg|2020-01-01 13:44:48|\n",
      "|          3|     Yes|            3rd|Heikkinen, Miss. ...|female|  26|              0|        0|STON/O2. 3101282|  7.925| null|Southampton|2020-01-01 13:38:11|\n",
      "|          4|     Yes|            1st|Futrelle, Mrs. Ja...|female|  35|              1|        0|          113803|   53.1| C123|Southampton|2020-01-01 13:32:00|\n",
      "|          5|      No|            3rd|Allen, Mr. Willia...|  male|  35|              0|        0|          373450|   8.05| null|Southampton|2020-01-01 13:36:30|\n",
      "|          6|      No|            3rd|    Moran, Mr. James|  male|null|              0|        0|          330877| 8.4583| null| Queenstown|2020-01-01 13:31:39|\n",
      "|          7|      No|            1st|McCarthy, Mr. Tim...|  male|  54|              0|        0|           17463|51.8625|  E46|Southampton|2020-01-01 13:37:31|\n",
      "|          8|      No|            3rd|Palsson, Master. ...|  male|   2|              3|        1|          349909| 21.075| null|Southampton|2020-01-01 13:49:08|\n",
      "|          9|     Yes|            3rd|Johnson, Mrs. Osc...|female|  27|              0|        2|          347742|11.1333| null|Southampton|2020-01-01 13:33:42|\n",
      "|         10|     Yes|            2nd|Nasser, Mrs. Nich...|female|  14|              1|        0|          237736|30.0708| null|  Cherbourg|2020-01-01 13:32:53|\n",
      "|         11|     Yes|            3rd|Sandstrom, Miss. ...|female|   4|              1|        1|         PP 9549|   16.7|   G6|Southampton|2020-01-01 13:32:23|\n",
      "|         12|     Yes|            1st|Bonnell, Miss. El...|female|  58|              0|        0|          113783|  26.55| C103|Southampton|2020-01-01 13:30:12|\n",
      "|         13|      No|            3rd|Saundercock, Mr. ...|  male|  20|              0|        0|       A/5. 2151|   8.05| null|Southampton|2020-01-01 13:33:34|\n",
      "|         14|      No|            3rd|Andersson, Mr. An...|  male|  39|              1|        5|          347082| 31.275| null|Southampton|2020-01-01 13:30:20|\n",
      "|         15|      No|            3rd|Vestrom, Miss. Hu...|female|  14|              0|        0|          350406| 7.8542| null|Southampton|2020-01-01 13:41:17|\n",
      "|         16|     Yes|            2nd|Hewlett, Mrs. (Ma...|female|  55|              0|        0|          248706|   16.0| null|Southampton|2020-01-01 13:34:22|\n",
      "|         17|      No|            3rd|Rice, Master. Eugene|  male|   2|              4|        1|          382652| 29.125| null| Queenstown|2020-01-01 13:41:55|\n",
      "|         18|     Yes|            2nd|Williams, Mr. Cha...|  male|null|              0|        0|          244373|   13.0| null|Southampton|2020-01-01 13:39:35|\n",
      "|         19|      No|            3rd|Vander Planke, Mr...|female|  31|              1|        0|          345763|   18.0| null|Southampton|2020-01-01 13:39:38|\n",
      "|         20|     Yes|            3rd|Masselmani, Mrs. ...|female|null|              0|        0|            2649|  7.225| null|  Cherbourg|2020-01-01 13:36:56|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e68a0-a614-458f-9d23-207e2a2cb5a2",
   "metadata": {},
   "source": [
    "## Now finding the Min,Max,and Avg here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681b6a12-1ba1-4742-86d8-37398785288d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_columns = [column[0] for column in df.dtypes if column[1] in ['int','float']]\n",
    "\n",
    "numerical_df = df.select(*numerical_columns).describe()\n",
    "summary_df = numerical_df.select(numerical_columns[1:]).summary('min','max','mean')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94e7dd0-45a3-43a3-b57c-d18d7da32ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+\n",
      "|summary|               Age|   Siblings_Spouse|        Par_child|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "|    min|                 0|                 0|                0|\n",
      "|    max|                80|               891|              891|\n",
      "|   mean|167.64315089562422|180.12515025772694|179.6375301872114|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605b558-95c7-4544-962b-78135256500a",
   "metadata": {},
   "source": [
    "## Here we Make the user define Function in which we change the last alphabets to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a28503d-5d42-4970-803b-52b4d4380bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "|PassengerId|Survived|Passenger_class|                Name|Gender| Age|Siblings_Spouse|Par_child|          Ticket|   Fare|Cabin|   Embarked|          Timestamp|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "|          1|      N1|            3r1|Braund, Mr. Owen ...|  male|  22|              1|        0|       A/5 21171|   7.25| null|Southampto1|2020-01-01 13:45:25|\n",
      "|          2|     Ye1|            1s1|Cumings, Mrs. Joh...|female|  38|              1|        0|        PC 17599|71.2833|  C85|  Cherbour1|2020-01-01 13:44:48|\n",
      "|          3|     Ye1|            3r1|Heikkinen, Miss. ...|female|  26|              0|        0|STON/O2. 3101282|  7.925| null|Southampto1|2020-01-01 13:38:11|\n",
      "|          4|     Ye1|            1s1|Futrelle, Mrs. Ja...|female|  35|              1|        0|          113803|   53.1| C123|Southampto1|2020-01-01 13:32:00|\n",
      "|          5|      N1|            3r1|Allen, Mr. Willia...|  male|  35|              0|        0|          373450|   8.05| null|Southampto1|2020-01-01 13:36:30|\n",
      "|          6|      N1|            3r1|    Moran, Mr. James|  male|null|              0|        0|          330877| 8.4583| null| Queenstow1|2020-01-01 13:31:39|\n",
      "|          7|      N1|            1s1|McCarthy, Mr. Tim...|  male|  54|              0|        0|           17463|51.8625|  E46|Southampto1|2020-01-01 13:37:31|\n",
      "|          8|      N1|            3r1|Palsson, Master. ...|  male|   2|              3|        1|          349909| 21.075| null|Southampto1|2020-01-01 13:49:08|\n",
      "|          9|     Ye1|            3r1|Johnson, Mrs. Osc...|female|  27|              0|        2|          347742|11.1333| null|Southampto1|2020-01-01 13:33:42|\n",
      "|         10|     Ye1|            2n1|Nasser, Mrs. Nich...|female|  14|              1|        0|          237736|30.0708| null|  Cherbour1|2020-01-01 13:32:53|\n",
      "|         11|     Ye1|            3r1|Sandstrom, Miss. ...|female|   4|              1|        1|         PP 9549|   16.7|   G6|Southampto1|2020-01-01 13:32:23|\n",
      "|         12|     Ye1|            1s1|Bonnell, Miss. El...|female|  58|              0|        0|          113783|  26.55| C103|Southampto1|2020-01-01 13:30:12|\n",
      "|         13|      N1|            3r1|Saundercock, Mr. ...|  male|  20|              0|        0|       A/5. 2151|   8.05| null|Southampto1|2020-01-01 13:33:34|\n",
      "|         14|      N1|            3r1|Andersson, Mr. An...|  male|  39|              1|        5|          347082| 31.275| null|Southampto1|2020-01-01 13:30:20|\n",
      "|         15|      N1|            3r1|Vestrom, Miss. Hu...|female|  14|              0|        0|          350406| 7.8542| null|Southampto1|2020-01-01 13:41:17|\n",
      "|         16|     Ye1|            2n1|Hewlett, Mrs. (Ma...|female|  55|              0|        0|          248706|   16.0| null|Southampto1|2020-01-01 13:34:22|\n",
      "|         17|      N1|            3r1|Rice, Master. Eugene|  male|   2|              4|        1|          382652| 29.125| null| Queenstow1|2020-01-01 13:41:55|\n",
      "|         18|     Ye1|            2n1|Williams, Mr. Cha...|  male|null|              0|        0|          244373|   13.0| null|Southampto1|2020-01-01 13:39:35|\n",
      "|         19|      N1|            3r1|Vander Planke, Mr...|female|  31|              1|        0|          345763|   18.0| null|Southampto1|2020-01-01 13:39:38|\n",
      "|         20|     Ye1|            3r1|Masselmani, Mrs. ...|female|null|              0|        0|            2649|  7.225| null|  Cherbour1|2020-01-01 13:36:56|\n",
      "+-----------+--------+---------------+--------------------+------+----+---------------+---------+----------------+-------+-----+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def change_last_letter(word):\n",
    "    return word[:-1] + '1'\n",
    "\n",
    "change_last_letter_udf = udf(change_last_letter, StringType())\n",
    "\n",
    "categorical_columns = ['Survived', 'Passenger_class', 'Embarked']  # Replace with your categorical column names\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df = df.withColumn(col, change_last_letter_udf(col))\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed166f8-49fd-41d5-8601-cb90a3b02a86",
   "metadata": {},
   "source": [
    "## In this line of code we make parquet file in which we save first column data which is sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c11b958-3aa2-4367-a53c-b7acf9f5e936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame called 'df'\n",
    "sorted_df = df.orderBy(df.columns[0])  # Sort by the first column\n",
    "\n",
    "sorted_df.write.parquet(\"titanic_sorted_data_file.parquet\")  # Save sorted DataFrame to Parquet file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49e3a7-1c15-4208-b2e8-3d89004dc19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
